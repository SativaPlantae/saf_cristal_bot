import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate

# ğŸŒ¿ Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ğŸŒ± ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ¦— Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# ğŸ“Š Carrega a planilha
df = pd.read_csv("dados/data.csv")

# Inicializa memÃ³ria real de conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# Boas-vindas (sÃ³ uma vez)
if "has_greeted" not in st.session_state:
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown("""
Oi! ğŸ˜Š  
Eu sou o SAFBot, seu ajudante aqui no SÃ­tio Cristal. Pode me perguntar qualquer coisa sobre as plantaÃ§Ãµes, os lucros, as espÃ©cies ou atÃ© como funciona esse tal de SAF.  
Prometo explicar como se fosse uma boa conversa no campo ğŸŒ¿ğŸŒ½
        """)
    st.session_state.has_greeted = True

# Modelo e cadeia com memÃ³ria
llm = ChatOpenAI(
    temperature=0.3,
    model="gpt-4o",
    openai_api_key=openai_key
)

prompt_template = PromptTemplate.from_template("""
VocÃª Ã© o SAFBot, um assistente simpÃ¡tico e acolhedor que conversa com pessoas que nÃ£o conhecem nada sobre agricultura ou tecnologia.

Responda com empatia, explicaÃ§Ãµes simples e num tom leve â€” como se estivesse explicando para um amigo curioso.

Use o histÃ³rico da conversa para manter o contexto da resposta e evitar repetiÃ§Ãµes desnecessÃ¡rias.

HistÃ³rico da conversa:
{history}

UsuÃ¡rio: {input}
SAFBot:
""")

conversation = ConversationChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.memory,
    verbose=False
)

# Campo de entrada
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")

# Exibir histÃ³rico (manual)
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []

for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(bot_msg)

# Nova interaÃ§Ã£o
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.chat_message("assistant", avatar="ğŸ¦—"):
        with st.spinner("Deixa eu pensar aqui..."):
            resposta = conversation.run(query)
        st.markdown(resposta)

    # Atualiza histÃ³rico visÃ­vel
    st.session_state.visible_history.append((query, resposta))

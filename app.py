import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAI
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# ğŸŒ± ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# ğŸŒ¿ Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ğŸ“Š Carrega os dados
df = pd.read_csv("dados/data.csv", sep=";")

# Corrige nomes das colunas
df.columns = [col.strip().lower().replace(" ", "_") for col in df.columns]

# ğŸ’¡ CorreÃ§Ã£o: converter colunas monetÃ¡rias
for col in ["faturamento_(r$)", "despesas_(r$)", "lucro_(r$)"]:
    df[col] = df[col].astype(str).str.replace("R$", "", regex=False).str.replace(".", "", regex=False).str.replace(",", ".", regex=False)
    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

# ğŸ§  MemÃ³ria da conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# ğŸ§¾ HistÃ³rico visÃ­vel
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot**, criado especialmente para conversar sobre o projeto agroflorestal do **SÃ­tio Cristal**.  
Pode me perguntar qualquer coisa sobre espÃ©cies plantadas, lucros, tipos de produto ou atÃ© mesmo o que Ã© um SAF.  
Fique Ã  vontade, eu explico tudo de forma bem simples! ğŸŒ¿
---
ğŸ“Œ Exemplos do que vocÃª pode perguntar:
- Quais espÃ©cies existem no SAF Cristal?
- Qual foi o lucro total?
- Quanto rende por ano, em mÃ©dia?
- Como esse sistema ajuda o meio ambiente?

Estou aqui pra conversar! ğŸ˜„
        """)

for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(bot_msg)

# ğŸ¤– Modelos
llm_chat = ChatOpenAI(temperature=0.3, model="gpt-4o", openai_api_key=openai_key)
llm_agent = OpenAI(temperature=0.3, openai_api_key=openai_key)

# ğŸ§® Agente para analisar os dados
agent = create_pandas_dataframe_agent(
    llm=llm_agent,
    df=df,
    verbose=False,
    handle_parsing_errors=True,
    allow_dangerous_code=True
)

# ğŸ” Detecta se deve consultar a planilha
def pergunta_envia_para_planilha(texto):
    palavras_chave = [
        "lucro", "renda", "espÃ©cie", "produzindo", "produÃ§Ã£o", "anos", "quantos", "valores",
        "despesa", "faturamento", "quanto", "receita", "ganho", "foi lucrado", "mÃ©dia", "total"
    ]
    return any(p in texto.lower() for p in palavras_chave)

# ğŸ§  CÃ¡lculos automÃ¡ticos
def calcular_metricas(df):
    anos = df["anos"].unique()
    duracao_em_anos = len(anos)

    total_faturamento = df["faturamento_(r$)"].sum()
    total_lucro = df["lucro_(r$)"].sum()
    total_despesas = df["despesas_(r$)"].sum()

    media_anual_faturamento = total_faturamento / duracao_em_anos
    media_mensal_faturamento = media_anual_faturamento / 12

    return {
        "anos": duracao_em_anos,
        "faturamento_total": total_faturamento,
        "lucro_total": total_lucro,
        "despesas_total": total_despesas,
        "faturamento_anual": media_anual_faturamento,
        "faturamento_mensal": media_mensal_faturamento
    }

metricas = calcular_metricas(df)

# Entrada do usuÃ¡rio
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")

if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    if pergunta_envia_para_planilha(query):
        try:
            resposta_dados = agent.run(query)
        except Exception as e:
            resposta_dados = f"(Desculpe, nÃ£o consegui acessar os dados agora: {str(e)})"
    else:
        resposta_dados = ""

    resumo_dados = (
        f"O projeto SAF Cristal tem duraÃ§Ã£o de aproximadamente {metricas['anos']} anos.\n"
        f"O faturamento total Ã© de aproximadamente R$ {metricas['faturamento_total']:,.2f}, "
        f"com lucro total de R$ {metricas['lucro_total']:,.2f} e despesas de R$ {metricas['despesas_total']:,.2f}.\n"
        f"Em mÃ©dia, fatura R$ {metricas['faturamento_anual']:,.2f} por ano, "
        f"o que equivale a cerca de R$ {metricas['faturamento_mensal']:,.2f} por mÃªs.\n"
    )

    prompt_inicial = (
        "VocÃª Ã© o SAFBot ğŸ, um assistente simples, didÃ¡tico e amigÃ¡vel. "
        "Evite termos tÃ©cnicos e responda como se estivesse conversando com alguÃ©m da comunidade rural. "
        "Use linguagem acessÃ­vel e explique com carinho e bom humor. Se estiver usando dados, "
        "utilize o resumo abaixo como referÃªncia adicional:\n\n"
        f"{resumo_dados}\n\n"
        f"Pergunta do usuÃ¡rio: {query}\n"
        f"{resposta_dados}"
    )

    resposta_final = ChatOpenAI(
        temperature=0.3, model="gpt-4o", openai_api_key=openai_key
    ).invoke(prompt_inicial).content

    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(resposta_final)

    st.session_state.visible_history.append((query, resposta_final))

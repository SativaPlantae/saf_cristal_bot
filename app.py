import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ğŸŒ¿ Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ğŸŒ± ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ¦— Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Pergunte como se fosse a um amigo curioso â€” ele fala a sua lÃ­ngua!")

# ğŸ“Š Carrega a planilha
df = pd.read_csv("dados/data.csv")

# ğŸ’¬ HistÃ³rico de conversa
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸ‘‹ Boas-vindas sÃ³ no inÃ­cio
if len(st.session_state.chat_history) == 0:
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot**, seu assistente aqui no SÃ­tio Cristal ğŸŒ¿  
Pode me perguntar qualquer coisa sobre as plantaÃ§Ãµes, o que estÃ¡ sendo produzido, quanto se gastou, o que deu lucro...  
NÃ£o se preocupe com palavras difÃ­ceis. Eu explico tudo de um jeito simples, como uma boa prosa na sombra de um pÃ© de aÃ§aÃ­ ğŸŒ³  
""")

# ğŸ§‘â€ğŸŒ¾ Entrada do usuÃ¡rio
query = st.chat_input("O que vocÃª quer saber sobre o SAF?")

# ğŸ§¾ Exibe o histÃ³rico anterior
for user_msg, bot_msg in st.session_state.chat_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(bot_msg)

# ğŸš€ Nova pergunta
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.chat_message("assistant", avatar="ğŸ¦—"):
        with st.spinner("Puxando conversa com o SAFBot..."):

            # ğŸ¤– Inicializa o modelo com GPT-4o
            llm = ChatOpenAI(
                temperature=0.2,
                model="gpt-4o",
                openai_api_key=openai_key
            )

            # ğŸ’¬ Prompt com linguagem acessÃ­vel e natural
            prompt_template = PromptTemplate.from_template("""
VocÃª Ã© um assistente simpÃ¡tico chamado SAFBot.

Seu pÃºblico sÃ£o pessoas que **nÃ£o sabem nada sobre inteligÃªncia artificial, agricultura ou SAF**.  
Explique tudo com **palavras simples**, seja acolhedor e humano.  
Fale como se estivesse conversando com um amigo da roÃ§a, sem usar jargÃµes ou termos tÃ©cnicos.  
DÃª exemplos prÃ¡ticos. Mantenha a resposta clara, leve e sem parecer que veio de uma mÃ¡quina.  
Sempre responda em **portuguÃªs brasileiro**.

Pergunta: {pergunta}
""")

            # ğŸ”— Cadeia para gerar respostas amigÃ¡veis
            chain = LLMChain(llm=llm, prompt=prompt_template)

            try:
                resposta = chain.run(pergunta=query)
            except Exception as e:
                resposta = f"âŒ Ocorreu um erro: {e}"

        st.markdown(resposta)

    # ğŸ“ Atualiza o histÃ³rico
    st.session_state.chat_history.append((query, resposta))

import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory

# ğŸŒ¿ Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ğŸŒ± ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# ğŸ“Š Carrega a planilha de dados
df = pd.read_csv("dados/data.csv")

# ğŸ§  MemÃ³ria da conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# ğŸ§¾ HistÃ³rico visual da conversa
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot**, criado especialmente para conversar sobre o projeto agroflorestal do **SÃ­tio Cristal**.  
Pode me perguntar qualquer coisa sobre espÃ©cies plantadas, lucros, tipos de produto ou atÃ© mesmo o que Ã© um SAF.  
Fique Ã  vontade, eu explico tudo de forma bem simples! ğŸŒ¿

---

ğŸ“Œ Exemplos do que vocÃª pode perguntar:
- Quais espÃ©cies tem no SAF Cristal?
- Qual foi o lucro em 2040?
- O que Ã© um SAF?
- Como esse sistema ajuda o meio ambiente?

Estou aqui pra conversar! ğŸ˜„
        """)

# ğŸ’¬ Mostra o histÃ³rico anterior
for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(bot_msg)

# ğŸ¤– Inicializa modelo OpenAI
llm = ChatOpenAI(
    temperature=0.3,
    model="gpt-4o",
    openai_api_key=openai_key
)

# ğŸ§  Cria o agente com base no DataFrame
agent = create_pandas_dataframe_agent(
    llm=llm,
    df=df,
    verbose=False,
    handle_parsing_errors=True,
    allow_dangerous_code=True
)

# ğŸ§‘â€ğŸŒ¾ Campo de entrada
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")

# Processa a pergunta
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.spinner("Consultando os dados do SAF Cristal..."):
        try:
            resposta = agent.run(query)
        except Exception as e:
            resposta = f"âŒ Ocorreu um erro: {str(e)}"

    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(resposta)

    # Salva o histÃ³rico para exibiÃ§Ã£o
    st.session_state.visible_history.append((query, resposta))

import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI

# Carregar variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ¦— Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. FaÃ§a perguntas como se estivesse no ChatGPT!")

# Carregar planilha
df = pd.read_csv("dados/data.csv")

# HistÃ³rico de conversa
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Campo de entrada
query = st.chat_input("Pergunte algo ao agente SAF:")

# Exibir histÃ³rico anterior
for user_msg, bot_msg in st.session_state.chat_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(bot_msg)

# Nova pergunta
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.chat_message("assistant", avatar="ğŸ¦—"):
        with st.spinner("Pensando..."):

            # CriaÃ§Ã£o do modelo com GPT-4o
            llm = ChatOpenAI(
                temperature=0,
                model="gpt-4o",
                openai_api_key=openai_key
            )

            # Agente com tratamento de erros e cÃ³digo liberado
            agent = create_pandas_dataframe_agent(
                llm,
                df,
                verbose=False,
                handle_parsing_errors=True,
                allow_dangerous_code=True
            )

            try:
                resposta = agent.run(query)
            except Exception as e:
                resposta = f"âŒ Ocorreu um erro: {e}"

        st.markdown(resposta)

    # Salvar no histÃ³rico
    st.session_state.chat_history.append((query, resposta))

import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAI
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ¿", layout="wide")
st.title("ğŸ Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# Carrega a planilha
df = pd.read_csv("dados/data.csv", sep=";")

# FunÃ§Ãµes de apoio

def faturamento_total(df):
    return df["faturamento (R$)"].sum()

def faturamento_mensal(df):
    return faturamento_total(df) / (df['anos'].nunique() * 12)

def faturamento_anual_medio(df):
    return faturamento_total(df) / df['anos'].nunique()

def duracao_saf(df):
    return df['anos'].nunique()

def ano_maior_menor_faturamento(df):
    agrupado = df.groupby('anos')["faturamento (R$)"].sum()
    maior = agrupado.idxmax()
    menor = agrupado.idxmin()
    return maior, menor

# MemÃ³ria de conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# HistÃ³rico visual
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot** ğŸ, seu assistente simpÃ¡tico e sempre pronto para ajudar. Como posso te ajudar hoje?
        """)

for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(bot_msg)

# Modelos
llm_chat = ChatOpenAI(temperature=0.3, model="gpt-4o", openai_api_key=openai_key)
llm_agent = OpenAI(temperature=0.3, openai_api_key=openai_key)

# Agente
agent = create_pandas_dataframe_agent(
    llm=llm_agent,
    df=df,
    verbose=False,
    handle_parsing_errors=True,
    allow_dangerous_code=True
)

conversation = ConversationChain(
    llm=llm_chat,
    memory=st.session_state.memory,
    verbose=False
)

# Regras para acionar respostas baseadas nos dados
perguntas_especiais = {
    "faturamento total": lambda: f"O faturamento total desse SAF Ã© de {faturamento_total(df):,.2f} reais.",
    "quantos anos": lambda: f"O SAF vai durar {duracao_saf(df)} anos.",
    "mÃ©dia por mÃªs": lambda: f"O faturamento mÃ©dio mensal Ã© de aproximadamente {faturamento_mensal(df):,.2f} reais.",
    "mÃ©dia por ano": lambda: f"O faturamento mÃ©dio anual Ã© de aproximadamente {faturamento_anual_medio(df):,.2f} reais.",
    "maior e menor": lambda: (
        lambda maior, menor: f"O ano de maior faturamento foi {maior} e o de menor faturamento foi {menor}."
    )(*ano_maior_menor_faturamento(df))
}

# Entrada do usuÃ¡rio
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    resposta = None
    for chave, funcao in perguntas_especiais.items():
        if chave in query.lower():
            resposta = funcao()
            break

    if not resposta:
        resposta = conversation.run(query)

    with st.chat_message("assistant", avatar="ğŸ"):
        st.markdown(resposta)

    st.session_state.visible_history.append((query, resposta))

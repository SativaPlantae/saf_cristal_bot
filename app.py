import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# ğŸŒ¿ Carrega variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ğŸŒ± Configura pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")

# ğŸŒ¾ TÃ­tulo e descriÃ§Ã£o
st.title("ğŸ¦— Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# Estilo customizado: botÃ£o no canto inferior direito
st.markdown("""
    <style>
        .fixed-button {
            position: fixed;
            bottom: 20px;
            right: 20px;
            z-index: 9999;
        }
    </style>
""", unsafe_allow_html=True)

# ğŸ” BotÃ£o "Nova conversa"
with st.container():
    if st.markdown('<div class="fixed-button">', unsafe_allow_html=True):
        if st.button("ğŸ”„ Nova conversa"):
            st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)
            st.session_state.visible_history = []
            st.experimental_rerun()
        st.markdown('</div>', unsafe_allow_html=True)

# ğŸ“Š Carrega dados (usado no futuro)
df = pd.read_csv("dados/data.csv")

# ğŸ§  MemÃ³ria da conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# ğŸ§¾ HistÃ³rico visÃ­vel (exibido no Streamlit)
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot**, criado especialmente para conversar sobre o projeto agroflorestal do **SÃ­tio Cristal**.  
Pode me perguntar qualquer coisa sobre espÃ©cies plantadas, lucros, tipos de produto ou atÃ© mesmo o que Ã© um SAF.  
Fique Ã  vontade, eu explico tudo de forma bem simples! ğŸŒ¿

---

ğŸ“Œ Exemplos do que vocÃª pode perguntar:
- Quais espÃ©cies tem no SAF Cristal?
- Qual foi o lucro em 2040?
- O que Ã© um SAF?
- Como esse sistema ajuda o meio ambiente?

Estou aqui pra conversar! ğŸ˜„
        """)

# ğŸ’¬ Mostra histÃ³rico anterior
for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(bot_msg)

# ğŸ¤– Modelo e cadeia com identidade SAFBot
llm = ChatOpenAI(
    temperature=0.3,
    model="gpt-4o",
    openai_api_key=openai_key
)

prompt_template = PromptTemplate.from_template("""
VocÃª Ã© o SAFBot ğŸŒ½ğŸ¦—, um assistente virtual criado especialmente para o projeto **SAF Cristal** â€” um Sistema Agroflorestal que mistura Ã¡rvores, cultivos agrÃ­colas e prÃ¡ticas sustentÃ¡veis no campo.

Seu papel Ã© **ajudar pessoas leigas** a entenderem os dados desse projeto com **explicaÃ§Ãµes simples, empÃ¡ticas e acolhedoras**, como se estivesse conversando com alguÃ©m da zona rural ou da comunidade local.

VocÃª foi treinado com base em uma **planilha com dados reais do SAF Cristal**, incluindo espÃ©cies, lucros, anos de produÃ§Ã£o, tipos de produtos e muito mais.

Sempre mantenha a conversa informal, respeitosa e evite termos tÃ©cnicos.  
VocÃª **nÃ£o precisa explicar que Ã© uma IA da OpenAI**.  
VocÃª Ã© o **SAFBot do SÃ­tio Cristal**, e fala com carinho sobre tudo que envolve esse projeto.

Use o histÃ³rico abaixo para manter o contexto da conversa:

{history}

UsuÃ¡rio: {input}
SAFBot:
""")

conversation = ConversationChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.memory,
    verbose=False
)

# ğŸ§‘â€ğŸŒ¾ Entrada do usuÃ¡rio
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")

if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.spinner("O SAFBot estÃ¡ pensando..."):
        resposta = conversation.run(query)

    # Renderiza APENAS uma vez
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(resposta)

    # Armazena no histÃ³rico visual (sem duplicaÃ§Ã£o!)
    st.session_state.visible_history.append((query, resposta))

import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# Carregar variÃ¡veis de ambiente
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="Agente SAF Cristal ğŸŒ±", layout="wide")
st.title("ğŸ¦— Agente Inteligente do SÃ­tio Cristal")
st.markdown("Converse com o agente sobre os dados do SAF. Ele fala fÃ¡cil, como quem troca ideia na varanda!")

# Carrega a planilha (opcional, vocÃª pode usar depois com ferramentas)
df = pd.read_csv("dados/data.csv")

# Inicia memÃ³ria da conversa
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

# Reiniciar conversa
if st.button("ğŸ”„ Nova conversa"):
    st.session_state.memory.clear()
    st.session_state.visible_history = []
    st.experimental_rerun()

# Mensagem de boas-vindas (somente na primeira interaÃ§Ã£o)
if "visible_history" not in st.session_state:
    st.session_state.visible_history = []
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown("""
OlÃ¡! ğŸ˜Š  
Eu sou o **SAFBot**, criado especialmente para conversar sobre o projeto agroflorestal do **SÃ­tio Cristal**.  
Pode me perguntar qualquer coisa sobre espÃ©cies plantadas, lucros, tipos de produto ou atÃ© mesmo o que Ã© um SAF.  
Fique Ã  vontade, eu explico tudo de forma bem simples! ğŸŒ¿

---

ğŸ“Œ Exemplos do que vocÃª pode perguntar:
- Quais espÃ©cies tem no SAF Cristal?
- Qual foi o lucro em 2040?
- O que Ã© um SAF?
- Como esse sistema ajuda o meio ambiente?

Estou aqui pra conversar! ğŸ˜„
        """)

# Modelo OpenAI com GPT-4o
llm = ChatOpenAI(
    temperature=0.3,
    model="gpt-4o",
    openai_api_key=openai_key
)

# Prompt com identidade definida do SAFBot
prompt_template = PromptTemplate.from_template("""
VocÃª Ã© o SAFBot ğŸŒ½ğŸ¦—, um assistente virtual criado especialmente para o projeto **SAF Cristal** â€” um Sistema Agroflorestal que mistura Ã¡rvores, cultivos agrÃ­colas e prÃ¡ticas sustentÃ¡veis no campo.

Seu papel Ã© **ajudar pessoas leigas** a entenderem os dados desse projeto com **explicaÃ§Ãµes simples, empÃ¡ticas e acolhedoras**, como se estivesse conversando com alguÃ©m da zona rural ou da comunidade local.

VocÃª foi treinado com base em uma **planilha com dados reais do SAF Cristal**, incluindo espÃ©cies, lucros, anos de produÃ§Ã£o, tipos de produtos e muito mais.

Sempre mantenha a conversa informal, respeitosa e evite termos tÃ©cnicos.  
VocÃª **nÃ£o precisa explicar que Ã© uma IA da OpenAI**.  
VocÃª Ã© o **SAFBot do SÃ­tio Cristal**, e fala com carinho sobre tudo que envolve esse projeto.

Use o histÃ³rico abaixo para manter o contexto da conversa:

{history}

UsuÃ¡rio: {input}
SAFBot:
""")

# Cria a cadeia de conversa
conversation = ConversationChain(
    llm=llm,
    prompt=prompt_template,
    memory=st.session_state.memory,
    verbose=False
)

# Exibe histÃ³rico de conversa anterior
for user_msg, bot_msg in st.session_state.visible_history:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(user_msg)
    with st.chat_message("assistant", avatar="ğŸ¦—"):
        st.markdown(bot_msg)

# Entrada do usuÃ¡rio
query = st.chat_input("Digite aqui sua pergunta sobre o SAF:")

# Se houver pergunta nova
if query:
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸŒ¾"):
        st.markdown(query)

    with st.chat_message("assistant", avatar="ğŸ¦—"):
        with st.spinner("Puxando na memÃ³ria do SAFBot..."):
            resposta = conversation.run(query)
        st.markdown(resposta)

    # Atualiza histÃ³rico visÃ­vel
    st.session_state.visible_history.append((query, resposta))
